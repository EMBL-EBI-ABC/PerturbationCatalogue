{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98f5bdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "import polars as pl\n",
    "from google.cloud import bigquery\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "import create_bq_table as cbq\n",
    "from upload_parquet_to_bq import upload_parquet_to_bq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560e9fce",
   "metadata": {},
   "source": [
    "# Define BigQuery project and dataset details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc1e2ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"unified_data\"\n",
    "project_id = \"prj-ext-dev-pertcat-437314\"\n",
    "dataset_id = f\"{project_id}.{dataset_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dac578",
   "metadata": {},
   "source": [
    "In the cells below, provide the `parquet_file_path`, `table_name`.\n",
    "\n",
    "`parquet_file_path` is the path to the parquet file you want to upload to BigQuery.\n",
    "`table_name` is the name of the table you want to create in BigQuery.\n",
    "\n",
    "For metadata, 4 tables are created:\n",
    "- `test_metadata_pc` - with partitioning and clustering\n",
    "- `test_metadata_p` - partitioning only\n",
    "- `test_metadata_c` - clustering only\n",
    "- `test_metadata_none` - no partitioning or clustering\n",
    "\n",
    "Since the tables already exist in BigQuery, this code shouldn't be run again, unless you delete the tables first (see last cell).\n",
    "\n",
    "To upload data to existing tables, you can use the `upload_parquet_to_bq`. This will upload data to a temporary table with appended suffix `_staging`, and, if the data is unique, it will be merged into the main table. This prevents accidentally uploading the same data multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874f605e",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff56cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file_path = \"../Perturbseq/curated/parquet/datlinger_2017_curated_long_metadata.parquet\"\n",
    "\n",
    "table_name=\"test_metadata\"\n",
    "\n",
    "df = pl.scan_parquet(parquet_file_path)\n",
    "schema = df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82673061",
   "metadata": {},
   "source": [
    "## Create tables in BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb7bfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partitioning and clustering\n",
    "ddl_sql_pc = cbq.generate_create_table_sql(\n",
    "    dataset_name=dataset_name,\n",
    "    table_name=table_name+\"_pc\",\n",
    "    schema=schema,\n",
    "    partition_column=\"perturbed_target_chromosome_encoding\",\n",
    "    partition_range_start=0,\n",
    "    partition_range_end=25,\n",
    "    partition_range_interval=1,\n",
    "    cluster_columns=['dataset_id', 'sample_id', 'perturbed_target_symbol']\n",
    ")\n",
    "\n",
    "cbq.create_bq_table(\n",
    "    project_id=project_id,\n",
    "    dataset_name=dataset_id,\n",
    "    ddl_sql=ddl_sql_pc\n",
    ")\n",
    "\n",
    "# Partitioning only\n",
    "ddl_sql_p = cbq.generate_create_table_sql(\n",
    "    dataset_name=dataset_name,\n",
    "    table_name=table_name+\"_p\",\n",
    "    schema=schema,\n",
    "    partition_column=\"perturbed_target_chromosome_encoding\",\n",
    "    partition_range_start=0,\n",
    "    partition_range_end=25,\n",
    "    partition_range_interval=1\n",
    ")\n",
    "\n",
    "cbq.create_bq_table(\n",
    "    project_id=project_id,\n",
    "    dataset_name=dataset_name,\n",
    "    ddl_sql=ddl_sql_p\n",
    ")\n",
    "\n",
    "# Clustering only\n",
    "ddl_sql_c = cbq.generate_create_table_sql(\n",
    "    dataset_name=dataset_name,\n",
    "    table_name=table_name+\"_c\",\n",
    "    schema=schema,\n",
    "    cluster_columns=['dataset_id', 'sample_id', 'perturbed_target_symbol']\n",
    ")\n",
    "\n",
    "cbq.create_bq_table(\n",
    "    project_id=project_id,\n",
    "    dataset_name=dataset_name,\n",
    "    ddl_sql=ddl_sql_c\n",
    ")\n",
    "\n",
    "# No partitioning or clustering\n",
    "ddl_sql_none = cbq.generate_create_table_sql(\n",
    "    dataset_name=dataset_name,\n",
    "    table_name=table_name+\"_none\",\n",
    "    schema=schema\n",
    ")\n",
    "\n",
    "cbq.create_bq_table(\n",
    "    project_id=project_id,\n",
    "    dataset_name=dataset_name,\n",
    "    ddl_sql=ddl_sql_none\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9007e8de",
   "metadata": {},
   "source": [
    "## Upload parquet files to BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dcf2a8",
   "metadata": {},
   "source": [
    "This uploads the parquet files to BigQuery tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169a78bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for table_name in [\"test_metadata_pc\", \"test_metadata_p\", \"test_metadata_c\", \"test_metadata_none\"]:\n",
    "    upload_parquet_to_bq(\n",
    "        parquet_path=parquet_file_path,\n",
    "        dataset_id=dataset_id,\n",
    "        table_name=table_name,\n",
    "        key_columns=['dataset_id', 'sample_id']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e9054e",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d87dfc",
   "metadata": {},
   "source": [
    "## Create a table in BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbea7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file_path = \"../Perturbseq/curated/parquet/datlinger_2017_curated_long_data.parquet\"\n",
    "table_name=\"test_data\"\n",
    "\n",
    "df = pl.scan_parquet(parquet_file_path)\n",
    "schema = df.schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70893953",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ddl_sql_data = cbq.generate_create_table_sql(\n",
    "    dataset_name=dataset_name,\n",
    "    table_name=table_name,\n",
    "    schema=schema,\n",
    "    cluster_columns=['dataset_id']\n",
    ")\n",
    "\n",
    "cbq.create_bq_table(\n",
    "    project_id=project_id,\n",
    "    dataset_name=dataset_name,\n",
    "    ddl_sql=ddl_sql_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b01fed1",
   "metadata": {},
   "source": [
    "## Upload parquet files to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a44d29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_parquet_to_bq(\n",
    "    parquet_path=parquet_file_path,\n",
    "    dataset_id=dataset_id,\n",
    "    table_name=table_name,\n",
    "    key_columns=['dataset_id', 'sample_id']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231af032",
   "metadata": {},
   "source": [
    "# Unified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302c4b03",
   "metadata": {},
   "source": [
    "## Create a table in BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f471e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file_path = \"../Perturbseq/curated/parquet/adamson_2016_upr_epistasis_curated_long_unified.parquet\"\n",
    "\n",
    "table_name=\"test_unified\"\n",
    "\n",
    "df = pl.scan_parquet(parquet_file_path)\n",
    "schema = df.schema\n",
    "\n",
    "ddl_sql_unified = cbq.generate_create_table_sql(\n",
    "    dataset_name=dataset_name,\n",
    "    table_name=table_name,\n",
    "    schema=schema,\n",
    "    cluster_columns=['dataset_id']\n",
    ")\n",
    "\n",
    "cbq.create_bq_table(\n",
    "    project_id=project_id,\n",
    "    dataset_name=dataset_name,\n",
    "    ddl_sql=ddl_sql_unified\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3469d22",
   "metadata": {},
   "source": [
    "## Upload parquet files to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9487b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_parquet_to_bq(\n",
    "    parquet_path=parquet_file_path,\n",
    "    dataset_id=dataset_id,\n",
    "    table_name=table_name,\n",
    "    key_columns=['dataset_id', 'sample_id']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cff08d",
   "metadata": {},
   "source": [
    "# Delete tables in BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0940c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of tables to delete\n",
    "tables_to_delete = [\n",
    "    # \"test_metadata_pc\",\n",
    "    # \"test_metadata_p\",\n",
    "    # \"test_metadata_c\",\n",
    "    # \"test_metadata_none\",\n",
    "    # \"test_metadata_pc_staging\",\n",
    "    # \"test_metadata_p_staging\",\n",
    "    # \"test_metadata_c_staging\",\n",
    "    # \"test_metadata_none_staging\"\n",
    "]\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "\n",
    "for table_name in tables_to_delete:\n",
    "    table_id = f\"{dataset_id}.{table_name}\"\n",
    "    try:\n",
    "        client.delete_table(table_id)\n",
    "        print(f\"Deleted table {table_id}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to delete table {table_id}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PerturbationCatalogue",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
